{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L09 05/04/224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning, Keras tuner implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning looks for the best parameters in your CNN implementation. This is done by optimizing a metric based on the validation sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can search for the best values in a dynamical model for the following parameters:\n",
    "- Integer hyperparameter with `hp.Int()`\n",
    "- Which activation function to use with `hp.Choice()`\n",
    "- Float hyperparameters (e.g. the learning rate) with `hp.Float()`\n",
    "- Add or remove layers with a boolean choice function with `hp.Boolean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt # the new boy in town\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from astropy.io import fits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from astropy.utils.data import download_file\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "version = 'pristine'\n",
    "file_url = 'https://archive.stsci.edu/hlsps/deepmerge/hlsp_deepmerge_hst-jwst_acs-wfc3-nircam_illustris-z2_f814w-f160w-f356w_v1_sim-'+version+'.fits'\n",
    "hdu = fits.open(download_file(file_url, cache=True, show_progress=True))\n",
    "\n",
    "X = np.asarray(hdu[0].data).astype('float32')\n",
    "y = np.asarray(hdu[1].data).astype('float32')\n",
    "\n",
    "X = np.asarray(hdu[0].data).astype('float32')\n",
    "y = np.asarray(hdu[1].data).astype('float32')\n",
    "\n",
    "random_state = 42\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=random_state)\n",
    "\n",
    "imsize = np.shape(X_train)[2]\n",
    "\n",
    "X_train = X_train.reshape(-1, imsize, imsize, 3)\n",
    "X_valtest = X_valtest.reshape(-1, imsize, imsize, 3)\n",
    "\n",
    "X_val = X_val.reshape(-1, imsize, imsize, 3)\n",
    "X_test = X_test.reshape(-1, imsize, imsize, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we define a dynamic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional layer 1\n",
    "    \n",
    "    hp_kernel_1 = hp.Int('kernel_1',\n",
    "                         min_value=4,\n",
    "                         max_value=10,\n",
    "                              step=2)\n",
    "    hp_kernel_size_1 = hp.Int('kernel_size_1',\n",
    "                              min_value=3,\n",
    "                              max_value=11,\n",
    "                                   step=2)\n",
    "    model.add(Conv2D(hp_kernel_1, (hp_kernel_size_1, hp_kernel_size_1), strides=(1, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Convolutional layer 2\n",
    "    \n",
    "    hp_kernel_2 = hp.Int('kernel_2',\n",
    "                         min_value=8,\n",
    "                         max_value=20,\n",
    "                              step=2)\n",
    "    hp_kernel_size_2 = hp.Int('kernel_size_2',\n",
    "                              min_value=3,\n",
    "                              max_value=11,\n",
    "                                   step=2)\n",
    "    model.add(Conv2D(hp_kernel_2, (hp_kernel_size_2, hp_kernel_size_2), strides=(1, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Convolutional layer 3\n",
    "    \n",
    "    hp_kernel_3 = hp.Int('kernel_3',\n",
    "                         min_value=16,\n",
    "                         max_value=40,\n",
    "                              step=2)\n",
    "    hp_kernel_size_3 = hp.Int('kernel_size_3',\n",
    "                              min_value=3,\n",
    "                              max_value=11,\n",
    "                                   step=2)\n",
    "    model.add(Conv2D(hp_kernel_3, (hp_kernel_size_3, hp_kernel_size_3), strides=(1, 1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    # Fully connected layer\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='softmax'))\n",
    "    model.add(Dense(32, activation='softmax'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # output layer\n",
    "\n",
    "    lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 100\n",
    "batch_size = 128\n",
    "shuffle = True\n",
    "\n",
    "stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "hyperpar_names =    ['kernel_1', 'kernel_size_1', 'kernel_2', 'kernel_size_2', 'kernel_3', 'kernel_size_3', 'learning_rate']\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=25,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='hypeparameter_optimization')\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs = nb_epochs, batch_size  = batch_size, shuffle = shuffle, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of tuners:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RandomSearch**, it doesn't learn from previously tested parameter combinations, and samples parameter combinations from a search space randomly\n",
    "- **BayesianOptimization**, doesn't sample hyperparameter combinations randomly, it follows a probabilistic approach under the hood. This approach takes into account already tested combinations and uses this information to sample the next combination for a test.\n",
    "- **Hyperband**, Optimized version of RandomSearch. The algorithm trains a large number of models for a few epochs and carries forward only the top-perfoming **half** of models to the next round. Hyperband determines the number of models to train in a bracket by computing $ 1 + \\log_{factor} (\\text{max\\_epochs}) $ and rounding it up to the next integer. It's like a tournament, round of 32, round of 16 ... semifinals, finals, winner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
